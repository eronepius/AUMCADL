{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c79eeae7-2b00-4766-b753-9e5f742e86c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam, SGD, Adagrad\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a8f26ec-37a3-4763-9884-7accbbf9aea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
       "0            6      148             72             35        0  33.6   \n",
       "1            1       85             66             29        0  26.6   \n",
       "2            8      183             64              0        0  23.3   \n",
       "3            1       89             66             23       94  28.1   \n",
       "4            0      137             40             35      168  43.1   \n",
       "\n",
       "   DiabetesPedigreeFunction  Age  Outcome  \n",
       "0                     0.627   50        1  \n",
       "1                     0.351   31        0  \n",
       "2                     0.672   32        1  \n",
       "3                     0.167   21        0  \n",
       "4                     2.288   33        1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./diabetes.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c45db9bb-d0df-40ee-b574-4d4b01cd459a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d8d24af-6daf-46cc-b4a2-65dbda22779a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n"
     ]
    }
   ],
   "source": [
    "cols = df.columns\n",
    "cols = list(cols)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88e23bc8-1647-4b07-9da4-47d5bde5272c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pregnancies</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.129459</td>\n",
       "      <td>0.141282</td>\n",
       "      <td>-0.081672</td>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.221898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glucose</th>\n",
       "      <td>0.129459</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.466581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BloodPressure</th>\n",
       "      <td>0.141282</td>\n",
       "      <td>0.152590</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>0.065068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkinThickness</th>\n",
       "      <td>-0.081672</td>\n",
       "      <td>0.057328</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>0.074752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Insulin</th>\n",
       "      <td>-0.073535</td>\n",
       "      <td>0.331357</td>\n",
       "      <td>0.088933</td>\n",
       "      <td>0.436783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.130548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMI</th>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.221071</td>\n",
       "      <td>0.281805</td>\n",
       "      <td>0.392573</td>\n",
       "      <td>0.197859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.292695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <td>-0.033523</td>\n",
       "      <td>0.137337</td>\n",
       "      <td>0.041265</td>\n",
       "      <td>0.183928</td>\n",
       "      <td>0.185071</td>\n",
       "      <td>0.140647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>0.173844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.544341</td>\n",
       "      <td>0.263514</td>\n",
       "      <td>0.239528</td>\n",
       "      <td>-0.113970</td>\n",
       "      <td>-0.042163</td>\n",
       "      <td>0.036242</td>\n",
       "      <td>0.033561</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.238356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Outcome</th>\n",
       "      <td>0.221898</td>\n",
       "      <td>0.466581</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.074752</td>\n",
       "      <td>0.130548</td>\n",
       "      <td>0.292695</td>\n",
       "      <td>0.173844</td>\n",
       "      <td>0.238356</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Pregnancies   Glucose  BloodPressure  SkinThickness  \\\n",
       "Pregnancies                  1.000000  0.129459       0.141282      -0.081672   \n",
       "Glucose                      0.129459  1.000000       0.152590       0.057328   \n",
       "BloodPressure                0.141282  0.152590       1.000000       0.207371   \n",
       "SkinThickness               -0.081672  0.057328       0.207371       1.000000   \n",
       "Insulin                     -0.073535  0.331357       0.088933       0.436783   \n",
       "BMI                          0.017683  0.221071       0.281805       0.392573   \n",
       "DiabetesPedigreeFunction    -0.033523  0.137337       0.041265       0.183928   \n",
       "Age                          0.544341  0.263514       0.239528      -0.113970   \n",
       "Outcome                      0.221898  0.466581       0.065068       0.074752   \n",
       "\n",
       "                           Insulin       BMI  DiabetesPedigreeFunction  \\\n",
       "Pregnancies              -0.073535  0.017683                 -0.033523   \n",
       "Glucose                   0.331357  0.221071                  0.137337   \n",
       "BloodPressure             0.088933  0.281805                  0.041265   \n",
       "SkinThickness             0.436783  0.392573                  0.183928   \n",
       "Insulin                   1.000000  0.197859                  0.185071   \n",
       "BMI                       0.197859  1.000000                  0.140647   \n",
       "DiabetesPedigreeFunction  0.185071  0.140647                  1.000000   \n",
       "Age                      -0.042163  0.036242                  0.033561   \n",
       "Outcome                   0.130548  0.292695                  0.173844   \n",
       "\n",
       "                               Age   Outcome  \n",
       "Pregnancies               0.544341  0.221898  \n",
       "Glucose                   0.263514  0.466581  \n",
       "BloodPressure             0.239528  0.065068  \n",
       "SkinThickness            -0.113970  0.074752  \n",
       "Insulin                  -0.042163  0.130548  \n",
       "BMI                       0.036242  0.292695  \n",
       "DiabetesPedigreeFunction  0.033561  0.173844  \n",
       "Age                       1.000000  0.238356  \n",
       "Outcome                   0.238356  1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dcd6c4c-c86c-4c64-bec4-5b85e2346722",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['Pregnancies','Glucose','BMI','Age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19ef25e7-a187-4d94-842b-d75211839b2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>33.6</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>26.6</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>23.3</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>28.1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>43.1</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose   BMI  Age\n",
       "0            6      148  33.6   50\n",
       "1            1       85  26.6   31\n",
       "2            8      183  23.3   32\n",
       "3            1       89  28.1   21\n",
       "4            0      137  43.1   33"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab2f8cf9-4c8d-4390-b29b-2cccf72eef49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    1\n",
       "Name: Outcome, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['Outcome']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22b2c3a5-e2b1-49c3-97f5-13694c9d8359",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.18, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1258c00c-2193-41ee-819b-04f9e7460e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = RandomOverSampler(sampling_strategy='minority', random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf514acb-26ea-40a1-b4c3-ee4e6c052925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(826, 4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45466346-a675-4084-9c88-37cbfabef6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b1493077-33ff-4212-9824-e42178bcf433",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f0be3da-a033-4a20-847a-bf9d59f432d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5764486 , -0.80159242,  0.15402396,  0.77723935])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3b004be-f1f5-4ccf-b38b-166a6c329c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(100, input_shape=(4,), kernel_initializer='normal', activation='tanh'))\n",
    "model.add(layers.Dropout(.5, input_shape=(2,)))\n",
    "model.add(layers.Dense(300, kernel_initializer='normal', activation='relu'))\n",
    "model.add(layers.Dropout(.1, input_shape=(2,)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f0cae00-061b-4084-92ae-49aae7202b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               500       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 300)               30300     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 300)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31,101\n",
      "Trainable params: 31,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31bd8c2e-c9e7-410b-b49e-840c5d800691",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b92a3d24-3ad5-4ab2-b99d-c6612a060409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "26/26 - 1s - loss: 0.5824 - accuracy: 0.7155 - val_loss: 0.5527 - val_accuracy: 0.7194 - 1s/epoch - 44ms/step\n",
      "Epoch 2/250\n",
      "26/26 - 0s - loss: 0.5171 - accuracy: 0.7324 - val_loss: 0.5698 - val_accuracy: 0.6978 - 90ms/epoch - 3ms/step\n",
      "Epoch 3/250\n",
      "26/26 - 0s - loss: 0.5090 - accuracy: 0.7421 - val_loss: 0.5729 - val_accuracy: 0.6978 - 91ms/epoch - 3ms/step\n",
      "Epoch 4/250\n",
      "26/26 - 0s - loss: 0.5055 - accuracy: 0.7312 - val_loss: 0.5644 - val_accuracy: 0.7050 - 92ms/epoch - 4ms/step\n",
      "Epoch 5/250\n",
      "26/26 - 0s - loss: 0.5038 - accuracy: 0.7349 - val_loss: 0.5616 - val_accuracy: 0.7050 - 88ms/epoch - 3ms/step\n",
      "Epoch 6/250\n",
      "26/26 - 0s - loss: 0.5028 - accuracy: 0.7337 - val_loss: 0.5560 - val_accuracy: 0.7050 - 91ms/epoch - 3ms/step\n",
      "Epoch 7/250\n",
      "26/26 - 0s - loss: 0.5065 - accuracy: 0.7361 - val_loss: 0.5682 - val_accuracy: 0.7050 - 92ms/epoch - 4ms/step\n",
      "Epoch 8/250\n",
      "26/26 - 0s - loss: 0.4974 - accuracy: 0.7373 - val_loss: 0.5653 - val_accuracy: 0.6978 - 94ms/epoch - 4ms/step\n",
      "Epoch 9/250\n",
      "26/26 - 0s - loss: 0.4996 - accuracy: 0.7349 - val_loss: 0.5682 - val_accuracy: 0.7050 - 90ms/epoch - 3ms/step\n",
      "Epoch 10/250\n",
      "26/26 - 0s - loss: 0.4975 - accuracy: 0.7361 - val_loss: 0.5544 - val_accuracy: 0.7122 - 87ms/epoch - 3ms/step\n",
      "Epoch 11/250\n",
      "26/26 - 0s - loss: 0.5018 - accuracy: 0.7421 - val_loss: 0.5624 - val_accuracy: 0.7266 - 86ms/epoch - 3ms/step\n",
      "Epoch 12/250\n",
      "26/26 - 0s - loss: 0.5049 - accuracy: 0.7361 - val_loss: 0.5611 - val_accuracy: 0.7050 - 90ms/epoch - 3ms/step\n",
      "Epoch 13/250\n",
      "26/26 - 0s - loss: 0.5008 - accuracy: 0.7312 - val_loss: 0.5541 - val_accuracy: 0.7050 - 99ms/epoch - 4ms/step\n",
      "Epoch 14/250\n",
      "26/26 - 0s - loss: 0.4991 - accuracy: 0.7458 - val_loss: 0.5676 - val_accuracy: 0.7122 - 86ms/epoch - 3ms/step\n",
      "Epoch 15/250\n",
      "26/26 - 0s - loss: 0.4926 - accuracy: 0.7312 - val_loss: 0.5594 - val_accuracy: 0.7194 - 89ms/epoch - 3ms/step\n",
      "Epoch 16/250\n",
      "26/26 - 0s - loss: 0.4962 - accuracy: 0.7324 - val_loss: 0.5591 - val_accuracy: 0.7266 - 87ms/epoch - 3ms/step\n",
      "Epoch 17/250\n",
      "26/26 - 0s - loss: 0.5016 - accuracy: 0.7421 - val_loss: 0.5655 - val_accuracy: 0.7122 - 92ms/epoch - 4ms/step\n",
      "Epoch 18/250\n",
      "26/26 - 0s - loss: 0.4916 - accuracy: 0.7433 - val_loss: 0.5593 - val_accuracy: 0.7266 - 90ms/epoch - 3ms/step\n",
      "Epoch 19/250\n",
      "26/26 - 0s - loss: 0.4955 - accuracy: 0.7409 - val_loss: 0.5574 - val_accuracy: 0.7410 - 115ms/epoch - 4ms/step\n",
      "Epoch 20/250\n",
      "26/26 - 0s - loss: 0.4826 - accuracy: 0.7542 - val_loss: 0.5613 - val_accuracy: 0.7338 - 89ms/epoch - 3ms/step\n",
      "Epoch 21/250\n",
      "26/26 - 0s - loss: 0.4905 - accuracy: 0.7433 - val_loss: 0.5700 - val_accuracy: 0.7338 - 89ms/epoch - 3ms/step\n",
      "Epoch 22/250\n",
      "26/26 - 0s - loss: 0.4965 - accuracy: 0.7385 - val_loss: 0.5736 - val_accuracy: 0.7410 - 87ms/epoch - 3ms/step\n",
      "Epoch 23/250\n",
      "26/26 - 0s - loss: 0.4904 - accuracy: 0.7530 - val_loss: 0.5648 - val_accuracy: 0.7338 - 87ms/epoch - 3ms/step\n",
      "Epoch 24/250\n",
      "26/26 - 0s - loss: 0.4888 - accuracy: 0.7470 - val_loss: 0.5641 - val_accuracy: 0.7410 - 89ms/epoch - 3ms/step\n",
      "Epoch 25/250\n",
      "26/26 - 0s - loss: 0.4950 - accuracy: 0.7409 - val_loss: 0.5780 - val_accuracy: 0.7338 - 91ms/epoch - 4ms/step\n",
      "Epoch 26/250\n",
      "26/26 - 0s - loss: 0.4924 - accuracy: 0.7446 - val_loss: 0.5657 - val_accuracy: 0.7410 - 91ms/epoch - 3ms/step\n",
      "Epoch 27/250\n",
      "26/26 - 0s - loss: 0.4878 - accuracy: 0.7433 - val_loss: 0.5710 - val_accuracy: 0.7410 - 88ms/epoch - 3ms/step\n",
      "Epoch 28/250\n",
      "26/26 - 0s - loss: 0.4863 - accuracy: 0.7385 - val_loss: 0.5669 - val_accuracy: 0.7410 - 89ms/epoch - 3ms/step\n",
      "Epoch 29/250\n",
      "26/26 - 0s - loss: 0.4854 - accuracy: 0.7421 - val_loss: 0.5701 - val_accuracy: 0.7266 - 90ms/epoch - 3ms/step\n",
      "Epoch 30/250\n",
      "26/26 - 0s - loss: 0.4908 - accuracy: 0.7433 - val_loss: 0.5800 - val_accuracy: 0.7266 - 91ms/epoch - 4ms/step\n",
      "Epoch 31/250\n",
      "26/26 - 0s - loss: 0.4902 - accuracy: 0.7506 - val_loss: 0.5599 - val_accuracy: 0.7554 - 91ms/epoch - 3ms/step\n",
      "Epoch 32/250\n",
      "26/26 - 0s - loss: 0.4933 - accuracy: 0.7385 - val_loss: 0.5555 - val_accuracy: 0.7482 - 88ms/epoch - 3ms/step\n",
      "Epoch 33/250\n",
      "26/26 - 0s - loss: 0.4817 - accuracy: 0.7433 - val_loss: 0.5597 - val_accuracy: 0.7410 - 90ms/epoch - 3ms/step\n",
      "Epoch 34/250\n",
      "26/26 - 0s - loss: 0.4885 - accuracy: 0.7373 - val_loss: 0.5585 - val_accuracy: 0.7554 - 90ms/epoch - 3ms/step\n",
      "Epoch 35/250\n",
      "26/26 - 0s - loss: 0.4905 - accuracy: 0.7409 - val_loss: 0.5800 - val_accuracy: 0.7410 - 91ms/epoch - 3ms/step\n",
      "Epoch 36/250\n",
      "26/26 - 0s - loss: 0.4829 - accuracy: 0.7530 - val_loss: 0.5527 - val_accuracy: 0.7482 - 87ms/epoch - 3ms/step\n",
      "Epoch 37/250\n",
      "26/26 - 0s - loss: 0.4843 - accuracy: 0.7446 - val_loss: 0.5667 - val_accuracy: 0.7266 - 93ms/epoch - 4ms/step\n",
      "Epoch 38/250\n",
      "26/26 - 0s - loss: 0.4871 - accuracy: 0.7518 - val_loss: 0.5576 - val_accuracy: 0.7482 - 89ms/epoch - 3ms/step\n",
      "Epoch 39/250\n",
      "26/26 - 0s - loss: 0.4839 - accuracy: 0.7458 - val_loss: 0.5568 - val_accuracy: 0.7482 - 90ms/epoch - 3ms/step\n",
      "Epoch 40/250\n",
      "26/26 - 0s - loss: 0.4783 - accuracy: 0.7530 - val_loss: 0.5678 - val_accuracy: 0.7554 - 92ms/epoch - 4ms/step\n",
      "Epoch 41/250\n",
      "26/26 - 0s - loss: 0.4825 - accuracy: 0.7397 - val_loss: 0.5563 - val_accuracy: 0.7554 - 90ms/epoch - 3ms/step\n",
      "Epoch 42/250\n",
      "26/26 - 0s - loss: 0.4853 - accuracy: 0.7433 - val_loss: 0.5515 - val_accuracy: 0.7482 - 89ms/epoch - 3ms/step\n",
      "Epoch 43/250\n",
      "26/26 - 0s - loss: 0.4845 - accuracy: 0.7518 - val_loss: 0.5567 - val_accuracy: 0.7482 - 90ms/epoch - 3ms/step\n",
      "Epoch 44/250\n",
      "26/26 - 0s - loss: 0.4809 - accuracy: 0.7542 - val_loss: 0.5635 - val_accuracy: 0.7482 - 92ms/epoch - 4ms/step\n",
      "Epoch 45/250\n",
      "26/26 - 0s - loss: 0.4819 - accuracy: 0.7506 - val_loss: 0.5723 - val_accuracy: 0.7482 - 90ms/epoch - 3ms/step\n",
      "Epoch 46/250\n",
      "26/26 - 0s - loss: 0.4778 - accuracy: 0.7542 - val_loss: 0.5694 - val_accuracy: 0.7482 - 90ms/epoch - 3ms/step\n",
      "Epoch 47/250\n",
      "26/26 - 0s - loss: 0.4808 - accuracy: 0.7458 - val_loss: 0.5757 - val_accuracy: 0.7410 - 90ms/epoch - 3ms/step\n",
      "Epoch 48/250\n",
      "26/26 - 0s - loss: 0.4813 - accuracy: 0.7446 - val_loss: 0.5644 - val_accuracy: 0.7626 - 89ms/epoch - 3ms/step\n",
      "Epoch 49/250\n",
      "26/26 - 0s - loss: 0.4762 - accuracy: 0.7615 - val_loss: 0.5642 - val_accuracy: 0.7482 - 90ms/epoch - 3ms/step\n",
      "Epoch 50/250\n",
      "26/26 - 0s - loss: 0.4807 - accuracy: 0.7458 - val_loss: 0.5621 - val_accuracy: 0.7482 - 89ms/epoch - 3ms/step\n",
      "Epoch 51/250\n",
      "26/26 - 0s - loss: 0.4785 - accuracy: 0.7433 - val_loss: 0.5626 - val_accuracy: 0.7410 - 89ms/epoch - 3ms/step\n",
      "Epoch 52/250\n",
      "26/26 - 0s - loss: 0.4775 - accuracy: 0.7567 - val_loss: 0.5635 - val_accuracy: 0.7482 - 88ms/epoch - 3ms/step\n",
      "Epoch 53/250\n",
      "26/26 - 0s - loss: 0.4699 - accuracy: 0.7554 - val_loss: 0.5599 - val_accuracy: 0.7482 - 88ms/epoch - 3ms/step\n",
      "Epoch 54/250\n",
      "26/26 - 0s - loss: 0.4815 - accuracy: 0.7603 - val_loss: 0.5587 - val_accuracy: 0.7626 - 89ms/epoch - 3ms/step\n",
      "Epoch 55/250\n",
      "26/26 - 0s - loss: 0.4794 - accuracy: 0.7446 - val_loss: 0.5524 - val_accuracy: 0.7482 - 89ms/epoch - 3ms/step\n",
      "Epoch 56/250\n",
      "26/26 - 0s - loss: 0.4777 - accuracy: 0.7518 - val_loss: 0.5748 - val_accuracy: 0.7410 - 84ms/epoch - 3ms/step\n",
      "Epoch 57/250\n",
      "26/26 - 0s - loss: 0.4706 - accuracy: 0.7676 - val_loss: 0.5592 - val_accuracy: 0.7626 - 88ms/epoch - 3ms/step\n",
      "Epoch 58/250\n",
      "26/26 - 0s - loss: 0.4749 - accuracy: 0.7591 - val_loss: 0.5559 - val_accuracy: 0.7554 - 89ms/epoch - 3ms/step\n",
      "Epoch 59/250\n",
      "26/26 - 0s - loss: 0.4827 - accuracy: 0.7542 - val_loss: 0.5682 - val_accuracy: 0.7410 - 89ms/epoch - 3ms/step\n",
      "Epoch 60/250\n",
      "26/26 - 0s - loss: 0.4714 - accuracy: 0.7639 - val_loss: 0.5611 - val_accuracy: 0.7482 - 86ms/epoch - 3ms/step\n",
      "Epoch 61/250\n",
      "26/26 - 0s - loss: 0.4717 - accuracy: 0.7603 - val_loss: 0.5562 - val_accuracy: 0.7554 - 89ms/epoch - 3ms/step\n",
      "Epoch 62/250\n",
      "26/26 - 0s - loss: 0.4844 - accuracy: 0.7518 - val_loss: 0.5460 - val_accuracy: 0.7482 - 95ms/epoch - 4ms/step\n",
      "Epoch 63/250\n",
      "26/26 - 0s - loss: 0.4735 - accuracy: 0.7651 - val_loss: 0.5483 - val_accuracy: 0.7554 - 87ms/epoch - 3ms/step\n",
      "Epoch 64/250\n",
      "26/26 - 0s - loss: 0.4686 - accuracy: 0.7688 - val_loss: 0.5439 - val_accuracy: 0.7482 - 88ms/epoch - 3ms/step\n",
      "Epoch 65/250\n",
      "26/26 - 0s - loss: 0.4714 - accuracy: 0.7712 - val_loss: 0.5630 - val_accuracy: 0.7482 - 88ms/epoch - 3ms/step\n",
      "Epoch 66/250\n",
      "26/26 - 0s - loss: 0.4688 - accuracy: 0.7482 - val_loss: 0.5582 - val_accuracy: 0.7482 - 90ms/epoch - 3ms/step\n",
      "Epoch 67/250\n",
      "26/26 - 0s - loss: 0.4743 - accuracy: 0.7591 - val_loss: 0.5622 - val_accuracy: 0.7410 - 89ms/epoch - 3ms/step\n",
      "Epoch 68/250\n",
      "26/26 - 0s - loss: 0.4676 - accuracy: 0.7579 - val_loss: 0.5481 - val_accuracy: 0.7482 - 90ms/epoch - 3ms/step\n",
      "Epoch 69/250\n",
      "26/26 - 0s - loss: 0.4812 - accuracy: 0.7615 - val_loss: 0.5712 - val_accuracy: 0.7338 - 84ms/epoch - 3ms/step\n",
      "Epoch 70/250\n",
      "26/26 - 0s - loss: 0.4676 - accuracy: 0.7663 - val_loss: 0.5566 - val_accuracy: 0.7482 - 90ms/epoch - 3ms/step\n",
      "Epoch 71/250\n",
      "26/26 - 0s - loss: 0.4799 - accuracy: 0.7591 - val_loss: 0.5396 - val_accuracy: 0.7482 - 89ms/epoch - 3ms/step\n",
      "Epoch 72/250\n",
      "26/26 - 0s - loss: 0.4723 - accuracy: 0.7736 - val_loss: 0.5653 - val_accuracy: 0.7482 - 90ms/epoch - 3ms/step\n",
      "Epoch 73/250\n",
      "26/26 - 0s - loss: 0.4702 - accuracy: 0.7676 - val_loss: 0.5626 - val_accuracy: 0.7482 - 91ms/epoch - 4ms/step\n",
      "Epoch 74/250\n",
      "26/26 - 0s - loss: 0.4736 - accuracy: 0.7615 - val_loss: 0.5549 - val_accuracy: 0.7410 - 89ms/epoch - 3ms/step\n",
      "Epoch 75/250\n",
      "26/26 - 0s - loss: 0.4797 - accuracy: 0.7591 - val_loss: 0.5527 - val_accuracy: 0.7410 - 89ms/epoch - 3ms/step\n",
      "Epoch 76/250\n",
      "26/26 - 0s - loss: 0.4684 - accuracy: 0.7688 - val_loss: 0.5697 - val_accuracy: 0.7410 - 91ms/epoch - 3ms/step\n",
      "Epoch 77/250\n",
      "26/26 - 0s - loss: 0.4783 - accuracy: 0.7676 - val_loss: 0.5588 - val_accuracy: 0.7554 - 91ms/epoch - 4ms/step\n",
      "Epoch 78/250\n",
      "26/26 - 0s - loss: 0.4666 - accuracy: 0.7712 - val_loss: 0.5629 - val_accuracy: 0.7554 - 93ms/epoch - 4ms/step\n",
      "Epoch 79/250\n",
      "26/26 - 0s - loss: 0.4672 - accuracy: 0.7724 - val_loss: 0.5610 - val_accuracy: 0.7554 - 91ms/epoch - 4ms/step\n",
      "Epoch 80/250\n",
      "26/26 - 0s - loss: 0.4784 - accuracy: 0.7554 - val_loss: 0.5410 - val_accuracy: 0.7554 - 120ms/epoch - 5ms/step\n",
      "Epoch 81/250\n",
      "26/26 - 0s - loss: 0.4657 - accuracy: 0.7809 - val_loss: 0.5696 - val_accuracy: 0.7410 - 90ms/epoch - 3ms/step\n",
      "Epoch 82/250\n",
      "26/26 - 0s - loss: 0.4677 - accuracy: 0.7676 - val_loss: 0.5512 - val_accuracy: 0.7482 - 85ms/epoch - 3ms/step\n",
      "Epoch 83/250\n",
      "26/26 - 0s - loss: 0.4720 - accuracy: 0.7712 - val_loss: 0.5608 - val_accuracy: 0.7554 - 91ms/epoch - 3ms/step\n",
      "Epoch 84/250\n",
      "26/26 - 0s - loss: 0.4699 - accuracy: 0.7615 - val_loss: 0.5606 - val_accuracy: 0.7482 - 90ms/epoch - 3ms/step\n",
      "Epoch 85/250\n",
      "26/26 - 0s - loss: 0.4671 - accuracy: 0.7736 - val_loss: 0.5474 - val_accuracy: 0.7554 - 87ms/epoch - 3ms/step\n",
      "Epoch 86/250\n",
      "26/26 - 0s - loss: 0.4686 - accuracy: 0.7639 - val_loss: 0.5521 - val_accuracy: 0.7554 - 90ms/epoch - 3ms/step\n",
      "Epoch 87/250\n",
      "26/26 - 0s - loss: 0.4668 - accuracy: 0.7603 - val_loss: 0.5611 - val_accuracy: 0.7338 - 90ms/epoch - 3ms/step\n",
      "Epoch 88/250\n",
      "26/26 - 0s - loss: 0.4683 - accuracy: 0.7663 - val_loss: 0.5291 - val_accuracy: 0.7410 - 90ms/epoch - 3ms/step\n",
      "Epoch 89/250\n",
      "26/26 - 0s - loss: 0.4722 - accuracy: 0.7579 - val_loss: 0.5556 - val_accuracy: 0.7482 - 90ms/epoch - 3ms/step\n",
      "Epoch 90/250\n",
      "26/26 - 0s - loss: 0.4680 - accuracy: 0.7736 - val_loss: 0.5435 - val_accuracy: 0.7554 - 90ms/epoch - 3ms/step\n",
      "Epoch 91/250\n",
      "26/26 - 0s - loss: 0.4623 - accuracy: 0.7627 - val_loss: 0.5523 - val_accuracy: 0.7482 - 90ms/epoch - 3ms/step\n",
      "Epoch 92/250\n",
      "26/26 - 0s - loss: 0.4619 - accuracy: 0.7797 - val_loss: 0.5399 - val_accuracy: 0.7482 - 91ms/epoch - 4ms/step\n",
      "Epoch 93/250\n",
      "26/26 - 0s - loss: 0.4712 - accuracy: 0.7615 - val_loss: 0.5559 - val_accuracy: 0.7482 - 90ms/epoch - 3ms/step\n",
      "Epoch 94/250\n",
      "26/26 - 0s - loss: 0.4715 - accuracy: 0.7615 - val_loss: 0.5454 - val_accuracy: 0.7410 - 90ms/epoch - 3ms/step\n",
      "Epoch 95/250\n",
      "26/26 - 0s - loss: 0.4600 - accuracy: 0.7663 - val_loss: 0.5324 - val_accuracy: 0.7338 - 92ms/epoch - 4ms/step\n",
      "Epoch 96/250\n",
      "26/26 - 0s - loss: 0.4726 - accuracy: 0.7506 - val_loss: 0.5557 - val_accuracy: 0.7482 - 96ms/epoch - 4ms/step\n",
      "Epoch 97/250\n",
      "26/26 - 0s - loss: 0.4631 - accuracy: 0.7809 - val_loss: 0.5563 - val_accuracy: 0.7410 - 99ms/epoch - 4ms/step\n",
      "Epoch 98/250\n",
      "26/26 - 0s - loss: 0.4596 - accuracy: 0.7881 - val_loss: 0.5376 - val_accuracy: 0.7410 - 109ms/epoch - 4ms/step\n",
      "Epoch 99/250\n",
      "26/26 - 0s - loss: 0.4648 - accuracy: 0.7688 - val_loss: 0.5475 - val_accuracy: 0.7410 - 89ms/epoch - 3ms/step\n",
      "Epoch 100/250\n",
      "26/26 - 0s - loss: 0.4554 - accuracy: 0.7833 - val_loss: 0.5353 - val_accuracy: 0.7338 - 87ms/epoch - 3ms/step\n",
      "Epoch 101/250\n",
      "26/26 - 0s - loss: 0.4618 - accuracy: 0.7797 - val_loss: 0.5751 - val_accuracy: 0.7410 - 87ms/epoch - 3ms/step\n",
      "Epoch 102/250\n",
      "26/26 - 0s - loss: 0.4719 - accuracy: 0.7615 - val_loss: 0.5458 - val_accuracy: 0.7338 - 87ms/epoch - 3ms/step\n",
      "Epoch 103/250\n",
      "26/26 - 0s - loss: 0.4646 - accuracy: 0.7724 - val_loss: 0.5324 - val_accuracy: 0.7410 - 89ms/epoch - 3ms/step\n",
      "Epoch 104/250\n",
      "26/26 - 0s - loss: 0.4568 - accuracy: 0.7663 - val_loss: 0.5439 - val_accuracy: 0.7410 - 89ms/epoch - 3ms/step\n",
      "Epoch 105/250\n",
      "26/26 - 0s - loss: 0.4651 - accuracy: 0.7724 - val_loss: 0.5325 - val_accuracy: 0.7338 - 92ms/epoch - 4ms/step\n",
      "Epoch 106/250\n",
      "26/26 - 0s - loss: 0.4676 - accuracy: 0.7748 - val_loss: 0.5384 - val_accuracy: 0.7410 - 89ms/epoch - 3ms/step\n",
      "Epoch 107/250\n",
      "26/26 - 0s - loss: 0.4637 - accuracy: 0.7615 - val_loss: 0.5353 - val_accuracy: 0.7266 - 92ms/epoch - 4ms/step\n",
      "Epoch 108/250\n",
      "26/26 - 0s - loss: 0.4722 - accuracy: 0.7676 - val_loss: 0.5390 - val_accuracy: 0.7482 - 89ms/epoch - 3ms/step\n",
      "Epoch 109/250\n",
      "26/26 - 0s - loss: 0.4628 - accuracy: 0.7542 - val_loss: 0.5325 - val_accuracy: 0.7482 - 92ms/epoch - 4ms/step\n",
      "Epoch 110/250\n",
      "26/26 - 0s - loss: 0.4610 - accuracy: 0.7724 - val_loss: 0.5455 - val_accuracy: 0.7410 - 84ms/epoch - 3ms/step\n",
      "Epoch 111/250\n",
      "26/26 - 0s - loss: 0.4505 - accuracy: 0.7845 - val_loss: 0.5377 - val_accuracy: 0.7410 - 90ms/epoch - 3ms/step\n",
      "Epoch 112/250\n",
      "26/26 - 0s - loss: 0.4524 - accuracy: 0.7785 - val_loss: 0.5306 - val_accuracy: 0.7338 - 87ms/epoch - 3ms/step\n",
      "Epoch 113/250\n",
      "26/26 - 0s - loss: 0.4631 - accuracy: 0.7663 - val_loss: 0.5568 - val_accuracy: 0.7338 - 89ms/epoch - 3ms/step\n",
      "Epoch 114/250\n",
      "26/26 - 0s - loss: 0.4562 - accuracy: 0.7809 - val_loss: 0.5456 - val_accuracy: 0.7266 - 89ms/epoch - 3ms/step\n",
      "Epoch 115/250\n",
      "26/26 - 0s - loss: 0.4653 - accuracy: 0.7821 - val_loss: 0.5318 - val_accuracy: 0.7266 - 88ms/epoch - 3ms/step\n",
      "Epoch 116/250\n",
      "26/26 - 0s - loss: 0.4470 - accuracy: 0.7748 - val_loss: 0.5380 - val_accuracy: 0.7266 - 91ms/epoch - 4ms/step\n",
      "Epoch 117/250\n",
      "26/26 - 0s - loss: 0.4627 - accuracy: 0.7554 - val_loss: 0.5384 - val_accuracy: 0.7266 - 90ms/epoch - 3ms/step\n",
      "Epoch 118/250\n",
      "26/26 - 0s - loss: 0.4535 - accuracy: 0.7809 - val_loss: 0.5322 - val_accuracy: 0.7410 - 123ms/epoch - 5ms/step\n",
      "Epoch 119/250\n",
      "26/26 - 0s - loss: 0.4530 - accuracy: 0.7772 - val_loss: 0.5456 - val_accuracy: 0.7410 - 88ms/epoch - 3ms/step\n",
      "Epoch 120/250\n",
      "26/26 - 0s - loss: 0.4592 - accuracy: 0.7663 - val_loss: 0.5354 - val_accuracy: 0.7266 - 88ms/epoch - 3ms/step\n",
      "Epoch 121/250\n",
      "26/26 - 0s - loss: 0.4621 - accuracy: 0.7785 - val_loss: 0.5527 - val_accuracy: 0.7482 - 86ms/epoch - 3ms/step\n",
      "Epoch 122/250\n",
      "26/26 - 0s - loss: 0.4607 - accuracy: 0.7615 - val_loss: 0.5479 - val_accuracy: 0.7410 - 90ms/epoch - 3ms/step\n",
      "Epoch 123/250\n",
      "26/26 - 0s - loss: 0.4474 - accuracy: 0.7797 - val_loss: 0.5419 - val_accuracy: 0.7410 - 91ms/epoch - 3ms/step\n",
      "Epoch 124/250\n",
      "26/26 - 0s - loss: 0.4608 - accuracy: 0.7821 - val_loss: 0.5293 - val_accuracy: 0.7266 - 90ms/epoch - 3ms/step\n",
      "Epoch 125/250\n",
      "26/26 - 0s - loss: 0.4560 - accuracy: 0.7736 - val_loss: 0.5371 - val_accuracy: 0.7266 - 94ms/epoch - 4ms/step\n",
      "Epoch 126/250\n",
      "26/26 - 0s - loss: 0.4632 - accuracy: 0.7688 - val_loss: 0.5233 - val_accuracy: 0.7410 - 98ms/epoch - 4ms/step\n",
      "Epoch 127/250\n",
      "26/26 - 0s - loss: 0.4368 - accuracy: 0.7893 - val_loss: 0.5424 - val_accuracy: 0.7338 - 101ms/epoch - 4ms/step\n",
      "Epoch 128/250\n",
      "26/26 - 0s - loss: 0.4457 - accuracy: 0.7772 - val_loss: 0.5303 - val_accuracy: 0.7266 - 90ms/epoch - 3ms/step\n",
      "Epoch 129/250\n",
      "26/26 - 0s - loss: 0.4647 - accuracy: 0.7542 - val_loss: 0.5372 - val_accuracy: 0.7410 - 91ms/epoch - 4ms/step\n",
      "Epoch 130/250\n",
      "26/26 - 0s - loss: 0.4537 - accuracy: 0.7809 - val_loss: 0.5188 - val_accuracy: 0.7554 - 90ms/epoch - 3ms/step\n",
      "Epoch 131/250\n",
      "26/26 - 0s - loss: 0.4509 - accuracy: 0.7639 - val_loss: 0.5391 - val_accuracy: 0.7554 - 90ms/epoch - 3ms/step\n",
      "Epoch 132/250\n",
      "26/26 - 0s - loss: 0.4650 - accuracy: 0.7663 - val_loss: 0.5445 - val_accuracy: 0.7266 - 89ms/epoch - 3ms/step\n",
      "Epoch 133/250\n",
      "26/26 - 0s - loss: 0.4561 - accuracy: 0.7833 - val_loss: 0.5372 - val_accuracy: 0.7482 - 88ms/epoch - 3ms/step\n",
      "Epoch 134/250\n",
      "26/26 - 0s - loss: 0.4595 - accuracy: 0.7797 - val_loss: 0.5376 - val_accuracy: 0.7410 - 88ms/epoch - 3ms/step\n",
      "Epoch 135/250\n",
      "26/26 - 0s - loss: 0.4545 - accuracy: 0.7676 - val_loss: 0.5301 - val_accuracy: 0.7338 - 87ms/epoch - 3ms/step\n",
      "Epoch 136/250\n",
      "26/26 - 0s - loss: 0.4525 - accuracy: 0.7833 - val_loss: 0.5399 - val_accuracy: 0.7482 - 87ms/epoch - 3ms/step\n",
      "Epoch 137/250\n",
      "26/26 - 0s - loss: 0.4546 - accuracy: 0.7772 - val_loss: 0.5351 - val_accuracy: 0.7554 - 92ms/epoch - 4ms/step\n",
      "Epoch 138/250\n",
      "26/26 - 0s - loss: 0.4584 - accuracy: 0.7724 - val_loss: 0.5315 - val_accuracy: 0.7338 - 90ms/epoch - 3ms/step\n",
      "Epoch 139/250\n",
      "26/26 - 0s - loss: 0.4504 - accuracy: 0.7748 - val_loss: 0.5446 - val_accuracy: 0.7410 - 88ms/epoch - 3ms/step\n",
      "Epoch 140/250\n",
      "26/26 - 0s - loss: 0.4414 - accuracy: 0.7785 - val_loss: 0.5375 - val_accuracy: 0.7410 - 91ms/epoch - 3ms/step\n",
      "Epoch 141/250\n",
      "26/26 - 0s - loss: 0.4542 - accuracy: 0.7797 - val_loss: 0.5262 - val_accuracy: 0.7266 - 91ms/epoch - 4ms/step\n",
      "Epoch 142/250\n",
      "26/26 - 0s - loss: 0.4493 - accuracy: 0.7797 - val_loss: 0.5272 - val_accuracy: 0.7410 - 84ms/epoch - 3ms/step\n",
      "Epoch 143/250\n",
      "26/26 - 0s - loss: 0.4449 - accuracy: 0.7881 - val_loss: 0.5342 - val_accuracy: 0.7482 - 92ms/epoch - 4ms/step\n",
      "Epoch 144/250\n",
      "26/26 - 0s - loss: 0.4498 - accuracy: 0.8027 - val_loss: 0.5341 - val_accuracy: 0.7266 - 92ms/epoch - 4ms/step\n",
      "Epoch 145/250\n",
      "26/26 - 0s - loss: 0.4465 - accuracy: 0.7845 - val_loss: 0.5295 - val_accuracy: 0.7266 - 90ms/epoch - 3ms/step\n",
      "Epoch 146/250\n",
      "26/26 - 0s - loss: 0.4550 - accuracy: 0.7615 - val_loss: 0.5304 - val_accuracy: 0.7410 - 90ms/epoch - 3ms/step\n",
      "Epoch 147/250\n",
      "26/26 - 0s - loss: 0.4542 - accuracy: 0.7748 - val_loss: 0.5141 - val_accuracy: 0.7338 - 88ms/epoch - 3ms/step\n",
      "Epoch 148/250\n",
      "26/26 - 0s - loss: 0.4503 - accuracy: 0.7857 - val_loss: 0.5348 - val_accuracy: 0.7338 - 86ms/epoch - 3ms/step\n",
      "Epoch 149/250\n",
      "26/26 - 0s - loss: 0.4504 - accuracy: 0.7869 - val_loss: 0.5410 - val_accuracy: 0.7338 - 89ms/epoch - 3ms/step\n",
      "Epoch 150/250\n",
      "26/26 - 0s - loss: 0.4562 - accuracy: 0.7676 - val_loss: 0.5319 - val_accuracy: 0.7410 - 89ms/epoch - 3ms/step\n",
      "Epoch 151/250\n",
      "26/26 - 0s - loss: 0.4465 - accuracy: 0.7676 - val_loss: 0.5406 - val_accuracy: 0.7338 - 84ms/epoch - 3ms/step\n",
      "Epoch 152/250\n",
      "26/26 - 0s - loss: 0.4589 - accuracy: 0.7857 - val_loss: 0.5272 - val_accuracy: 0.7482 - 89ms/epoch - 3ms/step\n",
      "Epoch 153/250\n",
      "26/26 - 0s - loss: 0.4412 - accuracy: 0.8027 - val_loss: 0.5306 - val_accuracy: 0.7554 - 89ms/epoch - 3ms/step\n",
      "Epoch 154/250\n",
      "26/26 - 0s - loss: 0.4538 - accuracy: 0.7760 - val_loss: 0.5478 - val_accuracy: 0.7482 - 125ms/epoch - 5ms/step\n",
      "Epoch 155/250\n",
      "26/26 - 0s - loss: 0.4384 - accuracy: 0.7857 - val_loss: 0.5244 - val_accuracy: 0.7482 - 90ms/epoch - 3ms/step\n",
      "Epoch 156/250\n",
      "26/26 - 0s - loss: 0.4473 - accuracy: 0.7785 - val_loss: 0.5414 - val_accuracy: 0.7482 - 93ms/epoch - 4ms/step\n",
      "Epoch 157/250\n",
      "26/26 - 0s - loss: 0.4364 - accuracy: 0.8002 - val_loss: 0.5444 - val_accuracy: 0.7482 - 96ms/epoch - 4ms/step\n",
      "Epoch 158/250\n",
      "26/26 - 0s - loss: 0.4426 - accuracy: 0.7918 - val_loss: 0.5260 - val_accuracy: 0.7482 - 84ms/epoch - 3ms/step\n",
      "Epoch 159/250\n",
      "26/26 - 0s - loss: 0.4445 - accuracy: 0.7869 - val_loss: 0.5254 - val_accuracy: 0.7554 - 90ms/epoch - 3ms/step\n",
      "Epoch 160/250\n",
      "26/26 - 0s - loss: 0.4525 - accuracy: 0.7712 - val_loss: 0.5371 - val_accuracy: 0.7554 - 89ms/epoch - 3ms/step\n",
      "Epoch 161/250\n",
      "26/26 - 0s - loss: 0.4468 - accuracy: 0.7785 - val_loss: 0.5216 - val_accuracy: 0.7554 - 89ms/epoch - 3ms/step\n",
      "Epoch 162/250\n",
      "26/26 - 0s - loss: 0.4420 - accuracy: 0.7772 - val_loss: 0.5318 - val_accuracy: 0.7410 - 89ms/epoch - 3ms/step\n",
      "Epoch 163/250\n",
      "26/26 - 0s - loss: 0.4465 - accuracy: 0.7845 - val_loss: 0.5130 - val_accuracy: 0.7554 - 92ms/epoch - 4ms/step\n",
      "Epoch 164/250\n",
      "26/26 - 0s - loss: 0.4529 - accuracy: 0.7845 - val_loss: 0.5482 - val_accuracy: 0.7338 - 97ms/epoch - 4ms/step\n",
      "Epoch 165/250\n",
      "26/26 - 0s - loss: 0.4362 - accuracy: 0.7966 - val_loss: 0.5288 - val_accuracy: 0.7410 - 103ms/epoch - 4ms/step\n",
      "Epoch 166/250\n",
      "26/26 - 0s - loss: 0.4454 - accuracy: 0.7736 - val_loss: 0.5252 - val_accuracy: 0.7554 - 104ms/epoch - 4ms/step\n",
      "Epoch 167/250\n",
      "26/26 - 0s - loss: 0.4421 - accuracy: 0.7857 - val_loss: 0.5488 - val_accuracy: 0.7338 - 105ms/epoch - 4ms/step\n",
      "Epoch 168/250\n",
      "26/26 - 0s - loss: 0.4395 - accuracy: 0.7942 - val_loss: 0.5226 - val_accuracy: 0.7410 - 110ms/epoch - 4ms/step\n",
      "Epoch 169/250\n",
      "26/26 - 0s - loss: 0.4430 - accuracy: 0.7821 - val_loss: 0.5503 - val_accuracy: 0.7410 - 117ms/epoch - 4ms/step\n",
      "Epoch 170/250\n",
      "26/26 - 0s - loss: 0.4431 - accuracy: 0.8002 - val_loss: 0.5216 - val_accuracy: 0.7410 - 108ms/epoch - 4ms/step\n",
      "Epoch 171/250\n",
      "26/26 - 0s - loss: 0.4498 - accuracy: 0.7893 - val_loss: 0.5271 - val_accuracy: 0.7338 - 106ms/epoch - 4ms/step\n",
      "Epoch 172/250\n",
      "26/26 - 0s - loss: 0.4457 - accuracy: 0.7772 - val_loss: 0.5347 - val_accuracy: 0.7482 - 114ms/epoch - 4ms/step\n",
      "Epoch 173/250\n",
      "26/26 - 0s - loss: 0.4507 - accuracy: 0.7809 - val_loss: 0.5333 - val_accuracy: 0.7482 - 117ms/epoch - 5ms/step\n",
      "Epoch 174/250\n",
      "26/26 - 0s - loss: 0.4504 - accuracy: 0.7833 - val_loss: 0.5208 - val_accuracy: 0.7554 - 107ms/epoch - 4ms/step\n",
      "Epoch 175/250\n",
      "26/26 - 0s - loss: 0.4476 - accuracy: 0.7857 - val_loss: 0.5339 - val_accuracy: 0.7410 - 109ms/epoch - 4ms/step\n",
      "Epoch 176/250\n",
      "26/26 - 0s - loss: 0.4348 - accuracy: 0.7930 - val_loss: 0.5263 - val_accuracy: 0.7482 - 106ms/epoch - 4ms/step\n",
      "Epoch 177/250\n",
      "26/26 - 0s - loss: 0.4389 - accuracy: 0.7881 - val_loss: 0.5334 - val_accuracy: 0.7482 - 101ms/epoch - 4ms/step\n",
      "Epoch 178/250\n",
      "26/26 - 0s - loss: 0.4481 - accuracy: 0.7772 - val_loss: 0.5367 - val_accuracy: 0.7482 - 96ms/epoch - 4ms/step\n",
      "Epoch 179/250\n",
      "26/26 - 0s - loss: 0.4346 - accuracy: 0.7906 - val_loss: 0.5394 - val_accuracy: 0.7482 - 98ms/epoch - 4ms/step\n",
      "Epoch 180/250\n",
      "26/26 - 0s - loss: 0.4355 - accuracy: 0.7833 - val_loss: 0.5269 - val_accuracy: 0.7410 - 108ms/epoch - 4ms/step\n",
      "Epoch 181/250\n",
      "26/26 - 0s - loss: 0.4477 - accuracy: 0.7881 - val_loss: 0.5329 - val_accuracy: 0.7482 - 110ms/epoch - 4ms/step\n",
      "Epoch 182/250\n",
      "26/26 - 0s - loss: 0.4563 - accuracy: 0.7942 - val_loss: 0.5439 - val_accuracy: 0.7482 - 107ms/epoch - 4ms/step\n",
      "Epoch 183/250\n",
      "26/26 - 0s - loss: 0.4418 - accuracy: 0.7857 - val_loss: 0.5217 - val_accuracy: 0.7410 - 112ms/epoch - 4ms/step\n",
      "Epoch 184/250\n",
      "26/26 - 0s - loss: 0.4412 - accuracy: 0.7845 - val_loss: 0.5379 - val_accuracy: 0.7410 - 107ms/epoch - 4ms/step\n",
      "Epoch 185/250\n",
      "26/26 - 0s - loss: 0.4422 - accuracy: 0.7833 - val_loss: 0.5253 - val_accuracy: 0.7410 - 108ms/epoch - 4ms/step\n",
      "Epoch 186/250\n",
      "26/26 - 0s - loss: 0.4445 - accuracy: 0.7857 - val_loss: 0.5400 - val_accuracy: 0.7482 - 159ms/epoch - 6ms/step\n",
      "Epoch 187/250\n",
      "26/26 - 0s - loss: 0.4398 - accuracy: 0.7906 - val_loss: 0.5275 - val_accuracy: 0.7410 - 108ms/epoch - 4ms/step\n",
      "Epoch 188/250\n",
      "26/26 - 0s - loss: 0.4324 - accuracy: 0.7869 - val_loss: 0.5278 - val_accuracy: 0.7410 - 109ms/epoch - 4ms/step\n",
      "Epoch 189/250\n",
      "26/26 - 0s - loss: 0.4455 - accuracy: 0.8039 - val_loss: 0.5159 - val_accuracy: 0.7410 - 106ms/epoch - 4ms/step\n",
      "Epoch 190/250\n",
      "26/26 - 0s - loss: 0.4435 - accuracy: 0.7966 - val_loss: 0.5198 - val_accuracy: 0.7410 - 110ms/epoch - 4ms/step\n",
      "Epoch 191/250\n",
      "26/26 - 0s - loss: 0.4379 - accuracy: 0.8027 - val_loss: 0.5447 - val_accuracy: 0.7482 - 105ms/epoch - 4ms/step\n",
      "Epoch 192/250\n",
      "26/26 - 0s - loss: 0.4515 - accuracy: 0.7845 - val_loss: 0.5232 - val_accuracy: 0.7338 - 114ms/epoch - 4ms/step\n",
      "Epoch 193/250\n",
      "26/26 - 0s - loss: 0.4310 - accuracy: 0.8015 - val_loss: 0.5277 - val_accuracy: 0.7482 - 109ms/epoch - 4ms/step\n",
      "Epoch 194/250\n",
      "26/26 - 0s - loss: 0.4411 - accuracy: 0.7785 - val_loss: 0.5140 - val_accuracy: 0.7482 - 108ms/epoch - 4ms/step\n",
      "Epoch 195/250\n",
      "26/26 - 0s - loss: 0.4403 - accuracy: 0.7906 - val_loss: 0.5139 - val_accuracy: 0.7554 - 92ms/epoch - 4ms/step\n",
      "Epoch 196/250\n",
      "26/26 - 0s - loss: 0.4383 - accuracy: 0.7760 - val_loss: 0.5277 - val_accuracy: 0.7410 - 98ms/epoch - 4ms/step\n",
      "Epoch 197/250\n",
      "26/26 - 0s - loss: 0.4480 - accuracy: 0.7785 - val_loss: 0.5155 - val_accuracy: 0.7482 - 98ms/epoch - 4ms/step\n",
      "Epoch 198/250\n",
      "26/26 - 0s - loss: 0.4372 - accuracy: 0.7869 - val_loss: 0.5358 - val_accuracy: 0.7410 - 100ms/epoch - 4ms/step\n",
      "Epoch 199/250\n",
      "26/26 - 0s - loss: 0.4360 - accuracy: 0.7918 - val_loss: 0.5227 - val_accuracy: 0.7410 - 111ms/epoch - 4ms/step\n",
      "Epoch 200/250\n",
      "26/26 - 0s - loss: 0.4401 - accuracy: 0.7869 - val_loss: 0.5291 - val_accuracy: 0.7554 - 96ms/epoch - 4ms/step\n",
      "Epoch 201/250\n",
      "26/26 - 0s - loss: 0.4312 - accuracy: 0.7966 - val_loss: 0.5492 - val_accuracy: 0.7410 - 109ms/epoch - 4ms/step\n",
      "Epoch 202/250\n",
      "26/26 - 0s - loss: 0.4351 - accuracy: 0.7821 - val_loss: 0.5270 - val_accuracy: 0.7410 - 113ms/epoch - 4ms/step\n",
      "Epoch 203/250\n",
      "26/26 - 0s - loss: 0.4316 - accuracy: 0.8039 - val_loss: 0.5425 - val_accuracy: 0.7410 - 100ms/epoch - 4ms/step\n",
      "Epoch 204/250\n",
      "26/26 - 0s - loss: 0.4233 - accuracy: 0.7881 - val_loss: 0.5406 - val_accuracy: 0.7410 - 92ms/epoch - 4ms/step\n",
      "Epoch 205/250\n",
      "26/26 - 0s - loss: 0.4393 - accuracy: 0.7881 - val_loss: 0.5289 - val_accuracy: 0.7554 - 96ms/epoch - 4ms/step\n",
      "Epoch 206/250\n",
      "26/26 - 0s - loss: 0.4268 - accuracy: 0.8015 - val_loss: 0.5391 - val_accuracy: 0.7410 - 97ms/epoch - 4ms/step\n",
      "Epoch 207/250\n",
      "26/26 - 0s - loss: 0.4229 - accuracy: 0.8002 - val_loss: 0.5276 - val_accuracy: 0.7338 - 103ms/epoch - 4ms/step\n",
      "Epoch 208/250\n",
      "26/26 - 0s - loss: 0.4395 - accuracy: 0.7869 - val_loss: 0.5218 - val_accuracy: 0.7482 - 105ms/epoch - 4ms/step\n",
      "Epoch 209/250\n",
      "26/26 - 0s - loss: 0.4289 - accuracy: 0.8027 - val_loss: 0.5339 - val_accuracy: 0.7482 - 103ms/epoch - 4ms/step\n",
      "Epoch 210/250\n",
      "26/26 - 0s - loss: 0.4372 - accuracy: 0.7881 - val_loss: 0.5385 - val_accuracy: 0.7338 - 89ms/epoch - 3ms/step\n",
      "Epoch 211/250\n",
      "26/26 - 0s - loss: 0.4359 - accuracy: 0.7930 - val_loss: 0.5151 - val_accuracy: 0.7554 - 91ms/epoch - 4ms/step\n",
      "Epoch 212/250\n",
      "26/26 - 0s - loss: 0.4500 - accuracy: 0.7797 - val_loss: 0.5185 - val_accuracy: 0.7410 - 134ms/epoch - 5ms/step\n",
      "Epoch 213/250\n",
      "26/26 - 0s - loss: 0.4486 - accuracy: 0.7881 - val_loss: 0.5270 - val_accuracy: 0.7410 - 96ms/epoch - 4ms/step\n",
      "Epoch 214/250\n",
      "26/26 - 0s - loss: 0.4283 - accuracy: 0.7857 - val_loss: 0.5253 - val_accuracy: 0.7338 - 91ms/epoch - 4ms/step\n",
      "Epoch 215/250\n",
      "26/26 - 0s - loss: 0.4397 - accuracy: 0.7772 - val_loss: 0.5092 - val_accuracy: 0.7482 - 88ms/epoch - 3ms/step\n",
      "Epoch 216/250\n",
      "26/26 - 0s - loss: 0.4400 - accuracy: 0.7748 - val_loss: 0.5394 - val_accuracy: 0.7410 - 97ms/epoch - 4ms/step\n",
      "Epoch 217/250\n",
      "26/26 - 0s - loss: 0.4390 - accuracy: 0.7942 - val_loss: 0.5190 - val_accuracy: 0.7410 - 110ms/epoch - 4ms/step\n",
      "Epoch 218/250\n",
      "26/26 - 0s - loss: 0.4366 - accuracy: 0.7918 - val_loss: 0.5211 - val_accuracy: 0.7554 - 105ms/epoch - 4ms/step\n",
      "Epoch 219/250\n",
      "26/26 - 0s - loss: 0.4376 - accuracy: 0.8039 - val_loss: 0.5351 - val_accuracy: 0.7554 - 115ms/epoch - 4ms/step\n",
      "Epoch 220/250\n",
      "26/26 - 0s - loss: 0.4352 - accuracy: 0.7942 - val_loss: 0.5077 - val_accuracy: 0.7410 - 97ms/epoch - 4ms/step\n",
      "Epoch 221/250\n",
      "26/26 - 0s - loss: 0.4272 - accuracy: 0.8002 - val_loss: 0.5233 - val_accuracy: 0.7410 - 95ms/epoch - 4ms/step\n",
      "Epoch 222/250\n",
      "26/26 - 0s - loss: 0.4337 - accuracy: 0.7942 - val_loss: 0.5154 - val_accuracy: 0.7410 - 104ms/epoch - 4ms/step\n",
      "Epoch 223/250\n",
      "26/26 - 0s - loss: 0.4354 - accuracy: 0.7906 - val_loss: 0.5345 - val_accuracy: 0.7410 - 138ms/epoch - 5ms/step\n",
      "Epoch 224/250\n",
      "26/26 - 0s - loss: 0.4433 - accuracy: 0.7809 - val_loss: 0.5384 - val_accuracy: 0.7338 - 114ms/epoch - 4ms/step\n",
      "Epoch 225/250\n",
      "26/26 - 0s - loss: 0.4404 - accuracy: 0.7978 - val_loss: 0.5343 - val_accuracy: 0.7410 - 102ms/epoch - 4ms/step\n",
      "Epoch 226/250\n",
      "26/26 - 0s - loss: 0.4295 - accuracy: 0.8039 - val_loss: 0.5207 - val_accuracy: 0.7554 - 108ms/epoch - 4ms/step\n",
      "Epoch 227/250\n",
      "26/26 - 0s - loss: 0.4319 - accuracy: 0.8075 - val_loss: 0.5396 - val_accuracy: 0.7554 - 111ms/epoch - 4ms/step\n",
      "Epoch 228/250\n",
      "26/26 - 0s - loss: 0.4432 - accuracy: 0.7821 - val_loss: 0.5431 - val_accuracy: 0.7554 - 101ms/epoch - 4ms/step\n",
      "Epoch 229/250\n",
      "26/26 - 0s - loss: 0.4227 - accuracy: 0.8063 - val_loss: 0.5301 - val_accuracy: 0.7482 - 96ms/epoch - 4ms/step\n",
      "Epoch 230/250\n",
      "26/26 - 0s - loss: 0.4384 - accuracy: 0.7833 - val_loss: 0.5371 - val_accuracy: 0.7482 - 96ms/epoch - 4ms/step\n",
      "Epoch 231/250\n",
      "26/26 - 0s - loss: 0.4438 - accuracy: 0.7954 - val_loss: 0.5105 - val_accuracy: 0.7410 - 96ms/epoch - 4ms/step\n",
      "Epoch 232/250\n",
      "26/26 - 0s - loss: 0.4344 - accuracy: 0.7833 - val_loss: 0.5082 - val_accuracy: 0.7338 - 103ms/epoch - 4ms/step\n",
      "Epoch 233/250\n",
      "26/26 - 0s - loss: 0.4346 - accuracy: 0.8002 - val_loss: 0.5068 - val_accuracy: 0.7482 - 99ms/epoch - 4ms/step\n",
      "Epoch 234/250\n",
      "26/26 - 0s - loss: 0.4329 - accuracy: 0.7881 - val_loss: 0.5377 - val_accuracy: 0.7410 - 95ms/epoch - 4ms/step\n",
      "Epoch 235/250\n",
      "26/26 - 0s - loss: 0.4237 - accuracy: 0.8015 - val_loss: 0.5221 - val_accuracy: 0.7410 - 100ms/epoch - 4ms/step\n",
      "Epoch 236/250\n",
      "26/26 - 0s - loss: 0.4374 - accuracy: 0.8111 - val_loss: 0.5196 - val_accuracy: 0.7410 - 101ms/epoch - 4ms/step\n",
      "Epoch 237/250\n",
      "26/26 - 0s - loss: 0.4304 - accuracy: 0.8087 - val_loss: 0.5333 - val_accuracy: 0.7554 - 103ms/epoch - 4ms/step\n",
      "Epoch 238/250\n",
      "26/26 - 0s - loss: 0.4207 - accuracy: 0.8027 - val_loss: 0.5387 - val_accuracy: 0.7482 - 146ms/epoch - 6ms/step\n",
      "Epoch 239/250\n",
      "26/26 - 0s - loss: 0.4337 - accuracy: 0.7797 - val_loss: 0.5384 - val_accuracy: 0.7482 - 96ms/epoch - 4ms/step\n",
      "Epoch 240/250\n",
      "26/26 - 0s - loss: 0.4282 - accuracy: 0.7966 - val_loss: 0.5126 - val_accuracy: 0.7410 - 93ms/epoch - 4ms/step\n",
      "Epoch 241/250\n",
      "26/26 - 0s - loss: 0.4228 - accuracy: 0.8099 - val_loss: 0.5210 - val_accuracy: 0.7482 - 94ms/epoch - 4ms/step\n",
      "Epoch 242/250\n",
      "26/26 - 0s - loss: 0.4284 - accuracy: 0.8002 - val_loss: 0.5251 - val_accuracy: 0.7338 - 108ms/epoch - 4ms/step\n",
      "Epoch 243/250\n",
      "26/26 - 0s - loss: 0.4383 - accuracy: 0.7869 - val_loss: 0.5493 - val_accuracy: 0.7554 - 106ms/epoch - 4ms/step\n",
      "Epoch 244/250\n",
      "26/26 - 0s - loss: 0.4235 - accuracy: 0.8148 - val_loss: 0.5268 - val_accuracy: 0.7482 - 98ms/epoch - 4ms/step\n",
      "Epoch 245/250\n",
      "26/26 - 0s - loss: 0.4324 - accuracy: 0.7906 - val_loss: 0.5226 - val_accuracy: 0.7338 - 94ms/epoch - 4ms/step\n",
      "Epoch 246/250\n",
      "26/26 - 0s - loss: 0.4269 - accuracy: 0.7966 - val_loss: 0.5094 - val_accuracy: 0.7482 - 112ms/epoch - 4ms/step\n",
      "Epoch 247/250\n",
      "26/26 - 0s - loss: 0.4282 - accuracy: 0.7857 - val_loss: 0.5024 - val_accuracy: 0.7338 - 107ms/epoch - 4ms/step\n",
      "Epoch 248/250\n",
      "26/26 - 0s - loss: 0.4341 - accuracy: 0.7893 - val_loss: 0.5350 - val_accuracy: 0.7410 - 109ms/epoch - 4ms/step\n",
      "Epoch 249/250\n",
      "26/26 - 0s - loss: 0.4381 - accuracy: 0.7930 - val_loss: 0.5305 - val_accuracy: 0.7482 - 107ms/epoch - 4ms/step\n",
      "Epoch 250/250\n",
      "26/26 - 0s - loss: 0.4424 - accuracy: 0.7893 - val_loss: 0.5265 - val_accuracy: 0.7554 - 97ms/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2480aa35f70>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=250, batch_size=32,  verbose=2, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d8cc9af-2854-4af7-b279-16883b255463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 0.5265 - accuracy: 0.7554\n",
      "Accuracy: 75.54\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e2af579-f2fc-468d-927a-35c9e20525c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_x = model.predict(X_test)\n",
    "classes_x=np.argmax(predict_x,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06011a27-bc3f-4f18-a3cc-4bfa0ad407f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
